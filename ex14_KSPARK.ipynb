{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d85006b",
   "metadata": {},
   "source": [
    "# EX14 Transformer Chatbot  \n",
    "## Objective  \n",
    "1. 한국어 전처리를 통해 학습 데이터셋을 구축하였다.  \n",
    "- 공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.  \n",
    "2. 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.  \n",
    "- 구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.  \n",
    "3. 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다.  \n",
    "- 한국어 입력문장에 맥락에 맞는 한국어로 답변을 리턴하였다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91d14869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995a734f",
   "metadata": {},
   "source": [
    "### Step 1.  데이터 수집하기\n",
    "한국어 챗봇 데이터는 송영숙님이 공개한 챗봇 데이터를 사용합니다  \n",
    "https://github.com/songys/Chatbot_data   \n",
    "일상다반사 0, 이별(부정) 1, 사랑(긍정) 2로 레이블링  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "595d654f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path=os.getenv('HOME') + '/aiffel/transformer_chatbot/data/ChatbotData .csv'\n",
    "original_data = pd.read_csv(file_path)\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47e506e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(original_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77772d80",
   "metadata": {},
   "source": [
    "총 11823개의 한국어 챗봇 데이터를 불러왔습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16cab13",
   "metadata": {},
   "source": [
    "### Step 2. 데이터 전처리하기  \n",
    "지난 요약 프로젝트에서 사용한 방법입니다  \n",
    "- 중복 제거  \n",
    "- 결측치 제거  \n",
    "- 텍스트 정규화  \n",
    "- 특수문자 제거  \n",
    "- 다시한번 결측치 제거  \n",
    "- 이상치 제거 (지나치게 긴 문장 등)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b5a7f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q        0\n",
       "A        0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#결측치확인\n",
    "original_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b67448fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#중복제거\n",
    "original_data = original_data.drop_duplicates()\n",
    "original_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aaa822",
   "metadata": {},
   "source": [
    "결측치와 중복은 없었습니다  \n",
    "정규화를 시켜줍니다  \n",
    "- 문장에서 단어와 구두점 사이에 공백을 추가  \n",
    "- 알파벳(한글)과 ! ? , . 이 4개의 구두점을 제외하고 다른 특수문자는 모두 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c68b500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "\n",
    "    # (한글, a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"^[ㄱ-ㅎ|가-힣|a-z|A-Z|0-9|]+$\", \" \", sentence)\n",
    "\n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "    # student와 온점 사이에 거리를 만듭니다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307d4e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = original_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cf9c85",
   "metadata": {},
   "source": [
    "### Step 3. SubwordTextEncoder 사용하기  \n",
    "한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야 한다고 많은 분이 알고 있습니다  \n",
    "하지만 여기서는 형태소 분석기가 아닌 실습에서 사용했던 내부 단어 토크나이저인 SubwordTextEncoder를 그대로 사용해봅니다  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c92c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a51413d",
   "metadata": {},
   "source": [
    "### Step 4. 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3e16c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b02c3109",
   "metadata": {},
   "source": [
    "### Step 5. 모델 평가하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6b23f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
