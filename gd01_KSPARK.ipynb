{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ce1197",
   "metadata": {},
   "source": [
    "# GD01 ResNet Ablation Study  \n",
    "## Objective  \n",
    "###  ResNet-34, ResNet-50 모델 구현이 정상적으로 진행되었는가?  \n",
    "- 블록함수 구현이 제대로 진행되었으며 구현한 모델의 summary가 예상된 형태로 출력되었다.  \n",
    "\n",
    "### 구현한 ResNet 모델을 활용하여 Image Classification 모델 훈련이 가능한가?  \n",
    "- tensorflow-datasets에서 제공하는 cats_vs_dogs 데이터셋으로 학습 진행 시 loss가 감소하는 것이 확인되었다.  \n",
    "\n",
    "### Ablation Study 결과가 바른 포맷으로 제출되었는가?  \n",
    "- ResNet-34, ResNet-50 각각 plain모델과 residual모델을  \n",
    "동일한 epoch만큼 학습시켰을 때의 validation accuracy 기준으로 Ablation Study 결과표가 작성되었다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9176d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b354d54e",
   "metadata": {},
   "source": [
    "### 1. 데이터셋 로드  \n",
    "Cifar-10 을 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1365a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66d71cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 162.17 MiB (download: 162.17 MiB, generated: 132.40 MiB, total: 294.58 MiB) to /aiffel/tensorflow_datasets/cifar10/3.0.2...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e2612b466b4e03ab1e3efc7cde427b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1fcd5ee34ad44b98a3dc423663f12a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a305978ece5344e5b9ae1607ed4dfb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling cifar10-train.tfrecord...:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling cifar10-test.tfrecord...:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset cifar10 downloaded and prepared to /aiffel/tensorflow_datasets/cifar10/3.0.2. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load('cifar10', split=['train', 'test'], shuffle_files = True, with_info = True ) \n",
    "#데이터셋명, 어떻게 나눌것인지, 파일 섞을것인지, 정보를 같이 불러올것인지 흠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d866771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='cifar10',\n",
       "    full_name='cifar10/3.0.2',\n",
       "    description=\"\"\"\n",
       "    The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
       "    \"\"\",\n",
       "    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',\n",
       "    data_path='/aiffel/tensorflow_datasets/cifar10/3.0.2',\n",
       "    download_size=162.17 MiB,\n",
       "    dataset_size=132.40 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'id': Text(shape=(), dtype=tf.string),\n",
       "        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=50000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@TECHREPORT{Krizhevsky09learningmultiple,\n",
       "        author = {Alex Krizhevsky},\n",
       "        title = {Learning multiple layers of features from tiny images},\n",
       "        institution = {},\n",
       "        year = {2009}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03fc9b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeaturesDict({\n",
       "    'id': Text(shape=(), dtype=tf.string),\n",
       "    'image': Image(shape=(32, 32, 3), dtype=tf.uint8),\n",
       "    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a236f8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(50000, shape=(), dtype=int64)\n",
      "tf.Tensor(10000, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 갯수 확인하는 코드랍니다\n",
    "print(tf.data.experimental.cardinality(ds_train))\n",
    "print(tf.data.experimental.cardinality(ds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e135c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_resize_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    # image = tf.image.resize(image, [32, 32])\n",
    "    return tf.cast(image, tf.float32) / 255., label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36b384f",
   "metadata": {},
   "source": [
    "### 2. 블록 구성하기   \n",
    "반복적인 네트워크 구조를 '블록화' 하여 구현합니다  \n",
    "주요 구조를 모듈화 시켜 하이퍼파라미터나 구조 변경시에 작업을 용이하게 진행할 수 있습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5872bc1",
   "metadata": {},
   "source": [
    "### VGG  \n",
    "신경망의 깊이가 기존과 다르게 많이 깊어지기 시작한 모델 (2014)   \n",
    "\n",
    "#### 구조  \n",
    "입력 이미지 > (Conv 반복 + Maxpool) 반복  ----- FC -----> Softmax  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f8bc5f",
   "metadata": {},
   "source": [
    "#### 블록 함수  \n",
    "conv는 Vgg16의 경우 3, Vgg 19의 경우 4 (일부 초기/후기 2/3) 을 쓰는걸 확인할 수 있음  \n",
    "괄호 안의 부분을 구현하게 됨  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d5c1b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conv2D 원형 (filters. kernel size, strides, padding, activation, input shape) 등 파라메터는 아래를 참고해서 넣자  \n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
    "\n",
    "#maxpool2D 원형(pool size, strides, padding, ) 등\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D\n",
    "\n",
    "def build_block_vgg(input_layer, num_cnn=3 , channel = 64, block_num = 1):\n",
    "    \n",
    "    x= input_layer\n",
    "    \n",
    "    #필터 수 = 채널 수\n",
    "    #kernel_size는 VGG에서는 '매우 작다'라는 표현과 함게 3,3으로 고정하여 사용\n",
    "    \n",
    "    for cnn_num in range(num_cnn):    \n",
    "        x = keras.layers.Conv2D(filters = channel, kernel_size = (3,3), activation = 'relu', \n",
    "                                kernel_initializer='he_normal', padding='same', name = f'block{block_num}_conv{cnn_num}' )(x)\n",
    "\n",
    "    x = keras.layers.MaxPool2D(pool_size = (2,2), strides = 2, name = f'block{block_num}_pooling')(x)    \n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f21ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#논문에 따르면 이후 레이어들은 공통으로 가짐\n",
    "#이 부분 반복작업이라 함수로 하나 뺏지만, 변동이 없을 예정이라 별도의 파라미터는 label수만 받기로 해요\n",
    "\n",
    "def build_tail_vgg(input_layer, output_num):\n",
    "    #fully-connected 4096 4096 1000 소맥\n",
    "    x = keras.layers.Flatten(name='flatten')(input_layer)\n",
    "    x = keras.layers.Dense(4096, activation = 'relu', name = 'fc1')(x)\n",
    "    x = keras.layers.Dense(4096, activation = 'relu', name = 'fc2')(x)\n",
    "    x = keras.layers.Dense(output_num, activation = 'softmax', name = 'prediction')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d745c70",
   "metadata": {},
   "source": [
    "#### 초기화 및 모델 구성   \n",
    "시작점 레이어 구성 후, 블록을 하나씩 붙여주게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5d3e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "\n",
    "num_labels = 10                          #라벨갯수\n",
    "floors = [2,2,3,3,3]                     #반복층수 [2 2 3 3 3], 층마다 필터수(같음) [64 128 256 512 512] \n",
    "filters  = [64, 128, 256, 512, 512]      #채널이랑 같은말\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9391deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input으로 쓰는 경우가 정확히 어떤경우일까? 과거 ex들 보면 input을 따로 쓰지 않았던 경우도 존재했음 (예 : 5)\n",
    "#https://smalldatalab.tistory.com/4 에 따르면 입력 데이터의 크기를 지정해주는 역할을 한다고는 하는데, 흠.. 꼭 필요할까요? \n",
    "#conv2D에서 입력수는 기존 레이어의 형태를 연결할때 자동으로 설정이 되긴 하는데ㅔㅔ, 처음에도 딱히 신경 안썼던거 같아서 ?\n",
    "\n",
    "vgg_16_input_layer = keras.layers.Input(shape = (32,32,3))\n",
    "\n",
    "#이런식으로 반복되려나\n",
    "#vgg = for build_block_vgg(vgg_input_layer, channels, num_cnn (이거 변수명 floor로 바꾸고싶네), channel_list, \n",
    "#                          num_classes 이건 출력갯수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4511b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://arxiv.org/pdf/1409.1556.pdf\n",
    "#논문에서 소개된 단위\n",
    "\n",
    "\n",
    "vgg_16_output_layer = vgg_16_input_layer\n",
    "\n",
    "for i in range(5):     #이 숫자가 block_num이 될것이에요\n",
    "    #num_cnn은 디폴트가 3이라 굳이 넣어줄 필요는 없음\n",
    "    vgg_16_output_layer = build_block_vgg(vgg_16_output_layer, num_cnn = floors[i], channel = filters[i], block_num = i)\n",
    "\n",
    "vgg_16_output_layer = build_tail_vgg(vgg_16_output_layer, num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13658811",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_16 = keras.Model(inputs=vgg_16_input_layer, outputs=vgg_16_output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcbc9e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block0_conv0 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block0_conv1 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block0_pooling (MaxPooling2D (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block1_conv0 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block1_pooling (MaxPooling2D (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block2_conv0 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block2_pooling (MaxPooling2D (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv0 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block3_pooling (MaxPooling2D (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv0 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pooling (MaxPooling2D (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "prediction (Dense)           (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 33,638,218\n",
      "Trainable params: 33,638,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_16.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d64ec7",
   "metadata": {},
   "source": [
    "lms에서 실습했던 스팩과 동일한 model이 생성되었습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c655549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mish / swish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5750573",
   "metadata": {},
   "source": [
    "### ResNet  \n",
    "Skip connection을 적용하여, VGG 혹은 이후에 소개되는 모델들이 가지는 Degradation을 Skip connection으로 해결하는 시도를 제안한 모델  \n",
    "\n",
    "#### 구조  \n",
    "resnet 34는 2층씩, resnet 50은 3층씩 동일한 필터수와 차원을 가진 네트워크의 블록구조를 가집니다  \n",
    "각 블록구조는 단계별로 3 / 4 / 6 / 3 번 반복됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5ad14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://arxiv.org/pdf/1512.03385.pdf\n",
    "#resnet 34는 2개 conv층 / 50은 3개 conv층, 풀링없음? 제일 마지막에 average pooling으로 정리\n",
    "\n",
    "floors_34 = 2\n",
    "floors_50  =3\n",
    "floor_iter = [3, 4, 6, 3]       #34, 50공통, 101 layers일때 [3, 4, 23, 3]\n",
    "\n",
    "channels = [64, 128, 256, 612]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8455ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_block_element_plain34(input_layer, channels, stage, block_num):     #stage 몇번째 단계인가\n",
    "    \n",
    "    x = input_layer\n",
    "    for i in range(floor_iter[stage]):        \n",
    "        x = keras.layers.conv2D(channels[stage], kernel_size = (3,3) ,activation = 'relu', \n",
    "                                kernel_initializer='he_normal', padding='same', name = f'block{block_num}_conv{cnn_num}' )(x)\n",
    "        \n",
    "        x = keras.layers.conv2D(channels[stage], kernel_size = (3,3) ,activation = 'relu', \n",
    "                                kernel_initializer='he_normal', padding='same', name = f'block{block_num}_conv{cnn_num}' )(x)\n",
    "\n",
    "        \n",
    "    return x\n",
    "        \n",
    "\n",
    "def build_block_element_plain50(input_layer, channels, stage, block_num):     #stage 몇번째 단계인가\n",
    "    \n",
    "    x = input_layer\n",
    "    for i in range(floor_iter[stage]):        \n",
    "        x = keras.layers.conv2D(channels[stage], kernel_size = (1,1) ,activation = 'relu', \n",
    "                                kernel_initializer='he_normal', padding='same', name = f'block{block_num}_conv{cnn_num}' )(x)\n",
    "        \n",
    "        x = keras.layers.conv2D(channels[stage], kernel_size = (3,3) ,activation = 'relu', \n",
    "                                kernel_initializer='he_normal', padding='same', name = f'block{block_num}_conv{cnn_num}' )(x)\n",
    "        \n",
    "        x = keras.layers.conv2D(channels[stage]*4, kernel_size = (1,1) ,activation = 'relu', \n",
    "                                kernel_initializer='he_normal', padding='same', name = f'block{block_num}_conv{cnn_num}' )(x)\n",
    "        \n",
    "    return x\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "def build_block_element_res50(input_layer, channels, floor_iter, block_num):\n",
    "    \n",
    "    x = input_layer\n",
    "    for i in range(floor_iter):\n",
    "        \n",
    "        x = keras.layers.conv2D(channels[i], kernel_size = (3,3) ,activation = 'relu', \n",
    "                                kernel_initializer='he_normal', padding='same', name = f'block{block_num}_conv{cnn_num}' )(x)\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    #여기서 x를 그대로 반환 / x+ input layer를 반환하는 분기점이 생기는 건지?\n",
    "    #그냥 +로 합치는 건지\n",
    "\n",
    "def build_block_res(input_layer, channels, floor_iter, ):\n",
    "    \n",
    "    x= input_layer\n",
    "    for i in range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b20724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet(input_shape=(32, 32,3), is_50=False):\n",
    "    \n",
    "    model = keras.layers.Input(shape = input_shape)\n",
    "    \n",
    "    if is_50 is true:\n",
    "        \n",
    "        model = build_resnet_50(input_shape, model)\n",
    "    \n",
    "    else:\n",
    "        model = build_resnet_34(input_shape, model)\n",
    "        \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e9b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet_34(input_shape, model):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b88802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet_50(input_shape, model):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a8051b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5240e792",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet_34 = build_resnet(input_shape=(32, 32,3), is_50=False)\n",
    "#resnet_34.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe9704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
